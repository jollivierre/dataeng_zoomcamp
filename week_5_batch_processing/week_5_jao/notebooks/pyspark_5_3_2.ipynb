{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d4b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/05 14:57:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# using the parquet files created in 5.3.1.\n",
    "# may need to recreate spark session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f496d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read parquest files into dataframe\n",
    "df_parquet = spark.read.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91e0537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hvfhs_license_num: string, dispatching_base_num: string, pickup_datetime: timestamp, dropoff_datetime: timestamp, PULocationID: int, DOLocationID: int, SR_Flag: double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataframe --> should also show column datatype based on schema\n",
    "df_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7882f57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#user freindly way of showing scehma\n",
    "df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a22dc328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[pickup_datetime: timestamp, dropoff_datetime: timestamp, PULocationID: int, DOLocationID: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of choosing needed cols -- > no data is shown\n",
    "df_parquet.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da9aa415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-05 15:25:51|2021-01-05 15:38:17|         229|         236|\n",
      "|2021-01-01 22:56:14|2021-01-01 23:06:41|          49|          80|\n",
      "|2021-01-01 01:51:36|2021-01-01 02:18:24|         197|          11|\n",
      "|2021-01-03 17:09:35|2021-01-03 17:29:54|          82|         101|\n",
      "|2021-01-05 14:07:12|2021-01-05 14:15:05|          72|          35|\n",
      "|2021-01-06 07:26:20|2021-01-06 07:45:31|           3|         128|\n",
      "|2021-01-03 15:27:46|2021-01-03 15:54:08|         164|         138|\n",
      "|2021-01-03 13:38:27|2021-01-03 13:50:05|         134|         196|\n",
      "|2021-01-05 17:51:58|2021-01-05 18:37:13|          82|         222|\n",
      "|2021-01-05 10:29:27|2021-01-05 10:44:56|         218|         265|\n",
      "|2021-01-06 10:46:40|2021-01-06 10:50:16|          84|          84|\n",
      "|2021-01-05 18:23:01|2021-01-05 18:33:27|         129|         260|\n",
      "|2021-01-05 20:30:36|2021-01-05 21:02:35|         132|         265|\n",
      "|2021-01-02 18:38:38|2021-01-02 18:56:16|         185|          47|\n",
      "|2021-01-03 09:58:19|2021-01-03 10:05:54|          61|          61|\n",
      "|2021-01-04 11:38:08|2021-01-04 12:01:17|         160|         112|\n",
      "|2021-01-03 18:29:42|2021-01-03 18:47:59|          75|         127|\n",
      "|2021-01-03 20:15:59|2021-01-03 20:39:27|          91|          40|\n",
      "|2021-01-06 16:00:30|2021-01-06 16:07:15|         227|         228|\n",
      "|2021-01-05 23:48:07|2021-01-06 00:02:58|         237|          24|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example of choosing needed cols, with filter -- > no data is shown unless .show() is added\n",
    "df_parquet.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(df_parquet.hvfhs_license_num == 'HV0003') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce022f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(pickup_datetime=datetime.datetime(2021, 1, 5, 15, 25, 51), dropoff_datetime=datetime.datetime(2021, 1, 5, 15, 38, 17), PULocationID=229, DOLocationID=236),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 1, 22, 56, 14), dropoff_datetime=datetime.datetime(2021, 1, 1, 23, 6, 41), PULocationID=49, DOLocationID=80),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 1, 1, 51, 36), dropoff_datetime=datetime.datetime(2021, 1, 1, 2, 18, 24), PULocationID=197, DOLocationID=11),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 3, 17, 9, 35), dropoff_datetime=datetime.datetime(2021, 1, 3, 17, 29, 54), PULocationID=82, DOLocationID=101),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 5, 14, 7, 12), dropoff_datetime=datetime.datetime(2021, 1, 5, 14, 15, 5), PULocationID=72, DOLocationID=35)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of choosing needed cols, with filter and surfacing top 5 --> head or take can be used\n",
    "df_parquet.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(df_parquet.hvfhs_license_num == 'HV0003') \\\n",
    "    .head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17af2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SQL would be easier that writing the query commands in spark\n",
    "# spark is more flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d9e3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that already exist in spark\n",
    "# convention used below as you can type \"F.\" then \"tab\" to see function list\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21f8652d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------+------------+------------+\n",
      "|dispatching_base_num|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+--------------------+-----------+------------+------------+------------+\n",
      "|              B02882| 2021-01-05|  2021-01-05|         229|         236|\n",
      "|              B02875| 2021-01-01|  2021-01-01|          49|          80|\n",
      "|              B02888| 2021-01-01|  2021-01-01|         197|          11|\n",
      "|              B02764| 2021-01-03|  2021-01-03|          82|         101|\n",
      "|              B02876| 2021-01-05|  2021-01-05|          72|          35|\n",
      "|              B02864| 2021-01-06|  2021-01-06|           3|         128|\n",
      "|              B02510| 2021-01-01|  2021-01-01|         168|         138|\n",
      "|              B02872| 2021-01-03|  2021-01-03|         164|         138|\n",
      "|              B02869| 2021-01-03|  2021-01-03|         134|         196|\n",
      "|              B02682| 2021-01-05|  2021-01-05|          82|         222|\n",
      "|              B02877| 2021-01-05|  2021-01-05|         218|         265|\n",
      "|              B02764| 2021-01-06|  2021-01-06|          84|          84|\n",
      "|              B02872| 2021-01-05|  2021-01-05|         129|         260|\n",
      "|              B02617| 2021-01-05|  2021-01-05|         132|         265|\n",
      "|              B02887| 2021-01-02|  2021-01-02|         185|          47|\n",
      "|              B02884| 2021-01-03|  2021-01-03|          61|          61|\n",
      "|              B02889| 2021-01-04|  2021-01-04|         160|         112|\n",
      "|              B02864| 2021-01-03|  2021-01-03|          75|         127|\n",
      "|              B02510| 2021-01-05|  2021-01-05|         255|         145|\n",
      "|              B02872| 2021-01-03|  2021-01-03|          91|          40|\n",
      "+--------------------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example of using to_date function\n",
    "# adding two new cols to dataframe and selecting cols accordingly\n",
    "# giving the name of \"new\" column with an existing column_name will overwrite the latter\n",
    "df_parquet \\\n",
    "    .withColumn('pickup_date', F.to_date(df_parquet.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df_parquet.dropoff_datetime)) \\\n",
    "    .select('dispatching_base_num', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5f9262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of creating a function\n",
    "# function is to take dispatching_base_num, and if divisible by 7 do x else do y\n",
    "# input is called base_num\n",
    "# from input start at position 1 and convert to int\n",
    "\n",
    "def check_base_num(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 ==0:\n",
    "        return f's/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7d09b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e/b30'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if function works\n",
    "check_base_num('B02864')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c888540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import schema method for pyspark (lives in sql.types).  \n",
    "# instead of importing one datatype separately, import entire package \n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bf2344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark udf\n",
    "# ensure types method is imported\n",
    "check_base_num_udf = F.udf(check_base_num, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "783d3192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-----------+------------+------------+------------+\n",
      "|dispatching_base_num|base_num_check|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+--------------------+--------------+-----------+------------+------------+------------+\n",
      "|              B02882|         e/b42| 2021-01-05|  2021-01-05|         229|         236|\n",
      "|              B02875|         e/b3b| 2021-01-01|  2021-01-01|          49|          80|\n",
      "|              B02888|         e/b48| 2021-01-01|  2021-01-01|         197|          11|\n",
      "|              B02764|         e/acc| 2021-01-03|  2021-01-03|          82|         101|\n",
      "|              B02876|         e/b3c| 2021-01-05|  2021-01-05|          72|          35|\n",
      "|              B02864|         e/b30| 2021-01-06|  2021-01-06|           3|         128|\n",
      "|              B02510|         e/9ce| 2021-01-01|  2021-01-01|         168|         138|\n",
      "|              B02872|         e/b38| 2021-01-03|  2021-01-03|         164|         138|\n",
      "|              B02869|         e/b35| 2021-01-03|  2021-01-03|         134|         196|\n",
      "|              B02682|         e/a7a| 2021-01-05|  2021-01-05|          82|         222|\n",
      "|              B02877|         s/b3d| 2021-01-05|  2021-01-05|         218|         265|\n",
      "|              B02764|         e/acc| 2021-01-06|  2021-01-06|          84|          84|\n",
      "|              B02872|         e/b38| 2021-01-05|  2021-01-05|         129|         260|\n",
      "|              B02617|         e/a39| 2021-01-05|  2021-01-05|         132|         265|\n",
      "|              B02887|         e/b47| 2021-01-02|  2021-01-02|         185|          47|\n",
      "|              B02884|         s/b44| 2021-01-03|  2021-01-03|          61|          61|\n",
      "|              B02889|         e/b49| 2021-01-04|  2021-01-04|         160|         112|\n",
      "|              B02864|         e/b30| 2021-01-03|  2021-01-03|          75|         127|\n",
      "|              B02510|         e/9ce| 2021-01-05|  2021-01-05|         255|         145|\n",
      "|              B02872|         e/b38| 2021-01-03|  2021-01-03|          91|          40|\n",
      "+--------------------+--------------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_parquet \\\n",
    "    .withColumn('pickup_date', F.to_date(df_parquet.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df_parquet.dropoff_datetime)) \\\n",
    "    .withColumn('base_num_check', check_base_num_udf(df_parquet.dispatching_base_num)) \\\n",
    "    .select('dispatching_base_num', 'base_num_check', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
